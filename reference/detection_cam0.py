#!/usr/bin/env python3
"""
rpicam-vid + OpenCVë¥¼ ì´ìš©í•œ ê°„ë‹¨í•œ ëª¨ì…˜ ê°ì§€ (ë¦¬íŒ©í† ë§ ë²„ì „) - Camera 0
ë‹¨ì¼ ì±…ì„ ì›ì¹™ ì ìš© - ê° ê¸°ëŠ¥ì„ ë³„ë„ í´ë˜ìŠ¤ë¡œ ë¶„ë¦¬

ì°¸ê³ :
- https://github.com/markschnabel/opencv-motion-detector
- https://github.com/youngsoul/rpi-motion-detection-background-subtraction
- https://pyimagesearch.com/2015/05/25/basic-motion-detection-and-tracking-with-python-and-opencv/

ë‚ ì§œ: 2025-09-05
"""

import cv2
import numpy as np
import subprocess
import time
import signal
import sys
import os
import threading
import tempfile
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from collections import deque
from abc import ABC, abstractmethod
from typing import Optional, List, Dict, Any

# ============================================================================
# ì „ì—­ ì„¤ì • ìƒìˆ˜ë“¤ (í•œëˆˆì— íŒŒì•… ê°€ëŠ¥)
# ============================================================================

# ëª¨ì…˜ ê°ì§€ ë¯¼ê°ë„ ì„¤ëª… (ì°¸ê³ ìš©)
## very_low: í™”ë©´ì˜ 3~5% ì´ìƒì´ ë³€í•´ì•¼ ê°ì§€(ì‚¬ëŒì´ ì§€ë‚˜ê°ˆ ë•Œ ì •ë„)
## low: íŒ” ì „ì²´ë¥¼ í”ë“¤ê±°ë‚˜ í° ë™ì‘ë§Œ ê°ì§€(ì‹¤ë‚´ ì¡°ëª… ë³€í™”ì— ì˜í–¥ ì—†ìŒ)
## medium: ì† ì „ì²´ë¥¼ í¬ê²Œ í”ë“¤ ë•Œë§Œ ê°ì§€(ì¼ìƒì  ì†ì§“)
## high: ì†ê°€ë½ ë“± ì‘ì€ ì›€ì§ì„ë„ ê°ì§€(ë…¸ì´ì¦ˆì— ë¯¼ê°, ì¡°ëª… ë³€í™” ì˜í–¥ ë°›ìŒ)
## very_high: ì¹´ë©”ë¼ í”ë“¤ë¦¼, ì¡°ëª… ë³€í™”, ë…¸ì´ì¦ˆê¹Œì§€ ê°ì§€(ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” false positive ë§ìŒ)
##
## ë¯¼ê°ë„ ë‹¨ê³„:1. ë„ˆë¬´ ì˜ˆë¯¼í•¨.
##
##  | ë‹¨ê³„       | ì„ê³„ê°’ | ì¿¨ë‹¤ìš´ | ì„¤ëª…                  |
##  |-----------|--------|-----|---------------------|
##  | very_low  | 5000px | 10ì´ˆ | ë§¤ìš° ë‚®ìŒ - ì‚¬ëŒì´ ê±¸ì–´ë‹¤ë‹ ë•Œë§Œ |
##  | low       | 2000px | 8ì´ˆ  | ë‚®ìŒ - í° ì†ì§“ë§Œ (í˜„ì¬ ì„¤ì •)  |
##  | medium    | 1500px | 6ì´ˆ  | ë³´í†µ - ì˜ë„ì ì¸ ì†ì›€ì§ì„ë§Œ     |
##  | high      | 200px  | 3ì´ˆ  | ë†’ìŒ - ì‘ì€ ì›€ì§ì„ë„        |
##  | very_high | 50px   | 2ì´ˆ  | ë§¤ìš° ë†’ìŒ - ì¹´ë©”ë¼ í”ë“¤ë¦¼ë„    |

## ë¯¼ê°ë„ ë‹¨ê³„:2. ë§ì´ ëœ ì˜ˆë¯¼í•¨. ì¡°ì •ê°’.
##
##  | ë‹¨ê³„       | ì„ê³„ê°’ | ì¿¨ë‹¤ìš´ | ì„¤ëª…                              |
##  |-----------|--------|-------|---------------------------------|
##  | very_low  | 10000px| 10ì´ˆ  | ë§¤ìš° ë‚®ìŒ - ì‚¬ëŒì´ í™”ë©´ì„ ê°€ë¡œì§ˆëŸ¬ì•¼ ê°ì§€ë¨   |
##  | low       | 6000px | 8ì´ˆ   | ë‚®ìŒ - íŒ” ì „ì²´ë¥¼ í”ë“¤ ë•Œë§Œ ê°ì§€           |
##  | medium    | 3500px | 6ì´ˆ   | ë³´í†µ - ì† ì „ì²´ë¥¼ í¬ê²Œ í”ë“¤ ë•Œë§Œ ê°ì§€       |
##  | high      | 1200px | 3ì´ˆ   | ë†’ìŒ - ì†ê°€ë½ ì›€ì§ì„ ë“± ì‘ì€ ì›€ì§ì„ë„ ê°ì§€   |
##  | very_high | 300px  | 2ì´ˆ   | ë§¤ìš° ë†’ìŒ - ë¯¸ì„¸í•œ ë³€í™”, ë…¸ì´ì¦ˆë„ ê°ì§€      |
##

# ëª¨ì…˜ ê°ì§€ ë¯¼ê°ë„ ë‹¨ê³„ (ì¡°ëª… ë³€í™”ì™€ ë…¸ì´ì¦ˆì— ë‘”ê°í•˜ê²Œ, ì‹¤ì œ ì‚¬ëŒ íŒ” ì›€ì§ì„ë§Œ ê°ì§€)
SENSITIVITY_LEVELS = {
    'very_low': {
        'threshold': 15000,     # ë§¤ìš° ë†’ì€ ì„ê³„ê°’ - ì‚¬ëŒì´ í™”ë©´ì„ í¬ê²Œ ê°€ë¡œì§ˆëŸ¬ì•¼ ê°ì§€
        'cooldown': 15,         # ê°ì§€ í›„ ëŒ€ê¸° ì‹œê°„ ê¹€ (ë” ê¸¸ê²Œ)
        'description': 'ë§¤ìš° ë‚®ìŒ - ì‚¬ëŒì´ í™”ë©´ì„ ê±°ì˜ ë‹¤ ê°€ë¡œì§ˆëŸ¬ì•¼ ê°ì§€'
    },
    'low': {
        'threshold': 10000,     # ë†’ì€ ì„ê³„ê°’ - íŒ” ì „ì²´ë¥¼ í¬ê²Œ í”ë“¤ ë•Œ ê°ì§€ (ë” ë†’ê²Œ)
        'cooldown': 12,         # ëŒ€ê¸° ì‹œê°„ ê¹€
        'description': 'ë‚®ìŒ - íŒ” ì „ì²´ë¥¼ í¬ê²Œ í”ë“¤ ë•Œ ì •ë„ ê°ì§€'
    },
    'medium': {
        'threshold': 6000,      # ë³´í†µ ì„ê³„ê°’ - íŒ”ì´ë‚˜ ì† ì „ì²´ê°€ ì›€ì§ì¼ ë•Œ ê°ì§€ (ë” ë†’ê²Œ)
        'cooldown': 8,          # ëŒ€ê¸° ì‹œê°„ ê¹€
        'description': 'ë³´í†µ - íŒ”ì´ë‚˜ ì† ì „ì²´ê°€ ì›€ì§ì¼ ë•Œë§Œ ê°ì§€'
    },
    'high': {
        'threshold': 3000,      # ë‚®ì€ ì„ê³„ê°’ - ì†ê°€ë½ ë“± ì‘ì€ ì›€ì§ì„ë„ ê°ì§€ (ë” ë†’ê²Œ)
        'cooldown': 5,          # ëŒ€ê¸° ì‹œê°„ ì§§ìŒ
        'description': 'ë†’ìŒ - ì†ê°€ë½ ë“± ì‘ì€ ë¬¼ì²´ ì›€ì§ì„ë„ ê°ì§€'
    },
    'very_high': {
        'threshold': 1000,      # ë§¤ìš° ë‚®ì€ ì„ê³„ê°’ - ë¯¸ì„¸í•œ ë³€í™”, ë…¸ì´ì¦ˆë„ ê°ì§€ (ë” ë†’ê²Œ)
        'cooldown': 3,          # ë§¤ìš° ì§§ì€ ëŒ€ê¸° ì‹œê°„
        'description': 'ë§¤ìš° ë†’ìŒ - ë¯¸ì„¸í•œ ë³€í™”, ë…¸ì´ì¦ˆê¹Œì§€ ê°ì§€'
    }
}

# í˜„ì¬ ë¯¼ê°ë„ ë‹¨ê³„ ì„¤ì •
CURRENT_SENSITIVITY = 'low'  # very_low, low, medium, high, very_high ì¤‘ì—ì„œ ì„ íƒ

# ëª¨ì…˜ ê°ì§€ê¸° íƒ€ì… ì„¤ì •
DETECTOR_TYPE = 'simple'  # simple, hand_wave ì¤‘ì—ì„œ ì„ íƒ

# ì¹´ë©”ë¼ ì„¤ì •
CAMERA_ID = 0  # Camera 0
FRAME_WIDTH = 640
FRAME_HEIGHT = 480
FRAMERATE = 30

# ì˜ìƒ ë…¹í™” ì„¤ì •
RECORDING_ENABLED = True  # ëª¨ì…˜ ê°ì§€ ì‹œ ì˜ìƒ ë…¹í™” í™œì„±í™”
RECORDING_WIDTH = 1280    # ë…¹í™” í•´ìƒë„ ê°€ë¡œ
RECORDING_HEIGHT = 720    # ë…¹í™” í•´ìƒë„ ì„¸ë¡œ
RECORDING_DURATION = 30   # ì´ ë…¹í™” ì‹œê°„(ì´ˆ) - í”„ë¦¬ë²„í¼ 5ì´ˆ + í¬ìŠ¤íŠ¸ 25ì´ˆ
PRE_BUFFER_DURATION = 5   # ëª¨ì…˜ ê°ì§€ ì´ì „ ë²„í¼ ì‹œê°„(ì´ˆ) - 5ì´ˆë¡œ ì„¤ì •
POST_BUFFER_DURATION = 25 # ëª¨ì…˜ ê°ì§€ ì´í›„ ë…¹í™” ì‹œê°„(ì´ˆ) - 25ì´ˆë¡œ ì„¤ì •

# í”„ë ˆì„ ê±´ë„ˆë›°ê¸° ë° ë°°ê²½ ì—…ë°ì´íŠ¸ ì£¼ê¸° ìƒìˆ˜í™”
SKIP_FRAME = 3
BG_UPDATE_FAST = 10
BG_UPDATE_SLOW = 30

# ë””ë²„ê·¸ ì„¤ì •
DEBUG_OUTPUT = True       # ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
SHOW_VIDEO = False        # ì‹¤ì‹œê°„ ì˜ìƒ ì°½ í‘œì‹œ (ì›ê²©ì—ì„œëŠ” ë¹„í™œì„±í™”)

# ============================================================================
# 1. ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤ (NEW)
# ============================================================================

class Config:
    """ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config_dict: dict = None):
        if config_dict is None:
            config_dict = self._get_default_config()
        
        self.camera = config_dict.get('camera', {})
        self.detection = config_dict.get('detection', {})
        self.recording = config_dict.get('recording', {})
        self.debug = config_dict.get('debug', {})
        
        # ë¯¼ê°ë„ ì„¤ì • ì ìš©
        self._apply_sensitivity_settings()
    
    def _get_default_config(self) -> dict:
        """ê¸°ë³¸ ì„¤ì • ë°˜í™˜ (ì „ì—­ ìƒìˆ˜ ì‚¬ìš©)"""
        return {
            'camera': {
                'id': CAMERA_ID,
                'width': FRAME_WIDTH,
                'height': FRAME_HEIGHT,
                'framerate': FRAMERATE
            },
            'detection': {
                'type': DETECTOR_TYPE,        # simple, hand_wave
                'sensitivity': CURRENT_SENSITIVITY,  # very_low, low, medium, high, very_high
                'skip_frames': SKIP_FRAME
            },
            'recording': {
                'enabled': RECORDING_ENABLED,
                'width': RECORDING_WIDTH,
                'height': RECORDING_HEIGHT,
                'duration': RECORDING_DURATION,
                'pre_buffer': PRE_BUFFER_DURATION,
                'post_buffer': POST_BUFFER_DURATION,
                'output_dir': 'videos/motion_events/cam0'  # cam0 ë””ë ‰í† ë¦¬
            },
            'debug': {
                'output': DEBUG_OUTPUT,
                'show_video': SHOW_VIDEO
            }
        }
    
    def _apply_sensitivity_settings(self):
        """ë¯¼ê°ë„ ì„¤ì •ì— ë”°ë¼ thresholdì™€ cooldown ì ìš©"""
        sensitivity = self.detection.get('sensitivity', CURRENT_SENSITIVITY)
        
        if sensitivity in SENSITIVITY_LEVELS:
            sensitivity_config = SENSITIVITY_LEVELS[sensitivity]
            self.detection['threshold'] = sensitivity_config['threshold']
            self.detection['cooldown'] = sensitivity_config['cooldown']
            self.detection['description'] = sensitivity_config['description']
        else:
            # ê¸°ë³¸ê°’ (CURRENT_SENSITIVITY ì„¤ì •)
            default_config = SENSITIVITY_LEVELS[CURRENT_SENSITIVITY]
            self.detection['threshold'] = default_config['threshold']
            self.detection['cooldown'] = default_config['cooldown']
            self.detection['description'] = default_config['description']
    
    def get_sensitivity_info(self) -> str:
        """í˜„ì¬ ë¯¼ê°ë„ ì •ë³´ ë°˜í™˜"""
        sensitivity = self.detection.get('sensitivity', CURRENT_SENSITIVITY)
        threshold = self.detection.get('threshold', 7000)
        cooldown = self.detection.get('cooldown', 8)
        description = self.detection.get('description', '')
        
        return f"ë¯¼ê°ë„: {sensitivity.upper()} | ì„ê³„ê°’: {threshold}px | ì¿¨ë‹¤ìš´: {cooldown}s | {description}"
    
    def list_available_sensitivities(self) -> str:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë¯¼ê°ë„ ëª©ë¡ ë°˜í™˜"""
        info_lines = ["ì‚¬ìš© ê°€ëŠ¥í•œ ë¯¼ê°ë„ ì„¤ì •:"]
        for level, config in SENSITIVITY_LEVELS.items():
            current_mark = " â† í˜„ì¬ ì„¤ì •" if level == CURRENT_SENSITIVITY else ""
            info_lines.append(f"  {level}: {config['threshold']}px, {config['cooldown']}s - {config['description']}{current_mark}")
        return "\n".join(info_lines)

# ============================================================================
# 2. ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ê´€ë¦¬ í´ë˜ìŠ¤ (EXTRACTED from SimpleMotionDetector)
# ============================================================================

class CameraStreamManager:
    """ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ê´€ë¦¬ ì „ë‹´ í´ë˜ìŠ¤"""
    
    def __init__(self, camera_id: int = 0, width: int = 640, height: int = 480, framerate: int = 30):
        self.camera_id = camera_id
        self.width = width
        self.height = height
        self.framerate = framerate
        self.process = None
        self.buffer = b""
        
    def start_stream(self) -> bool:
        """rpicam-vid MJPEG ìŠ¤íŠ¸ë¦¼ ì‹œì‘"""
        cmd = [
            "rpicam-vid",
            "--camera", str(self.camera_id),
            "--width", str(self.width),
            "--height", str(self.height),
            "--framerate", str(self.framerate),
            "--timeout", "0",  # ë¬´í•œ
            "--nopreview",
            "--codec", "mjpeg",
            "--quality", "80",
            "--flush", "1",
            "--output", "-"  # stdout
        ]

        try:
            self.process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                bufsize=0,
                preexec_fn=os.setsid
            )
            print("Camera stream started")
            return True
        except Exception as e:
            print(f"Failed to start camera: {e}")
            return False
    
    def stop_stream(self):
        """ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€"""
        if self.process and self.process.poll() is None:
            try:
                os.killpg(os.getpgid(self.process.pid), signal.SIGTERM)
                self.process.wait(timeout=3)
            except:
                try:
                    os.killpg(os.getpgid(self.process.pid), signal.SIGKILL)
                except:
                    pass
        self.process = None
        self.buffer = b""
    
    def restart_stream(self) -> bool:
        """ìŠ¤íŠ¸ë¦¼ ì¬ì‹œì‘"""
        self.stop_stream()
        time.sleep(2)
        return self.start_stream()
    
    def is_streaming(self) -> bool:
        """ìŠ¤íŠ¸ë¦¼ ìƒíƒœ í™•ì¸"""
        return self.process is not None and self.process.poll() is None
    
    def get_frame(self) -> Optional[np.ndarray]:
        """ë‹¤ìŒ í”„ë ˆì„ ë°˜í™˜"""
        if not self.is_streaming():
            return None
            
        try:
            chunk = self.process.stdout.read(4096)
            if not chunk:
                return None
        except Exception:
            return None

        self.buffer += chunk
        
        frame, self.buffer = self._extract_frame_from_mjpeg(self.buffer)
        return frame
    
    def _extract_frame_from_mjpeg(self, buffer: bytes) -> tuple:
        """MJPEG ìŠ¤íŠ¸ë¦¼ì—ì„œ JPEG í”„ë ˆì„ ì¶”ì¶œ"""
        start_marker = b'\xff\xd8'  # JPEG ì‹œì‘
        end_marker = b'\xff\xd9'    # JPEG ë

        start_pos = buffer.find(start_marker)
        end_pos = buffer.find(end_marker, start_pos)

        if start_pos >= 0 and end_pos > start_pos:
            jpeg_data = buffer[start_pos:end_pos + 2]
            remaining_buffer = buffer[end_pos + 2:]

            try:
                frame = cv2.imdecode(np.frombuffer(jpeg_data, dtype=np.uint8), cv2.IMREAD_COLOR)
                return frame, remaining_buffer
            except:
                return None, remaining_buffer

        return None, buffer

    def test_camera(self) -> bool:
        """ì¹´ë©”ë¼ í…ŒìŠ¤íŠ¸"""
        test_cmd = ["rpicam-hello", "--camera", str(self.camera_id), "--timeout", "1000"]
        try:
            result = subprocess.run(test_cmd, capture_output=True, timeout=10)
            return result.returncode == 0
        except Exception:
            return False

# ============================================================================
# 3. ëª¨ì…˜ ê°ì§€ ì•Œê³ ë¦¬ì¦˜ í´ë˜ìŠ¤ë“¤ (EXTRACTED from SimpleMotionDetector)
# ============================================================================

class MotionDetectorBase(ABC):
    """ëª¨ì…˜ ê°ì§€ê¸° ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤"""
    
    @abstractmethod
    def detect(self, frame: np.ndarray) -> bool:
        """ëª¨ì…˜ ê°ì§€ ìˆ˜í–‰"""
        pass
    
    @abstractmethod
    def reset(self):
        """ê°ì§€ê¸° ìƒíƒœ ì´ˆê¸°í™”"""
        pass
    
    @abstractmethod
    def is_ready(self) -> bool:
        """ê°ì§€ê¸° ì¤€ë¹„ ìƒíƒœ í™•ì¸"""
        pass

class SimpleMotionDetector(MotionDetectorBase):
    """ë‹¨ìˆœ ë°°ê²½ ì°¨ë¶„ë²• ëª¨ì…˜ ê°ì§€ê¸°"""
    
    def __init__(self, threshold: int = 7000, cooldown: int = 8, debug: bool = True):
        self.threshold = threshold
        self.cooldown = cooldown
        self.debug = debug
        self.last_detection_time = 0
        self.background_frame = None
        self.background_frames = deque(maxlen=60)
        self.background_ready = False
        self.frame_count = 0
        
        # ìƒìˆ˜ë“¤
        self.GAUSSIAN_BLUR_SIZE = 11
        self.DELTA_THRESHOLD = 25
        self.BG_UPDATE_FAST = 10
        self.BG_UPDATE_SLOW = 30
        
    def detect(self, frame: np.ndarray) -> bool:
        """ë‹¨ìˆœ ëª¨ì…˜ ê°ì§€"""
        current_time = time.time()
        self.frame_count += 1
        
        # ì¿¨ë‹¤ìš´ ì²´í¬
        if current_time - self.last_detection_time < self.cooldown:
            return False

        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ ë° ë¸”ëŸ¬
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (self.GAUSSIAN_BLUR_SIZE, self.GAUSSIAN_BLUR_SIZE), 0)

        # ë°°ê²½ ì•ˆì •í™” (60í”„ë ˆì„)
        if len(self.background_frames) < 60:
            self.background_frames.append(gray.copy())
            if len(self.background_frames) == 60:
                self.background_frame = np.median(self.background_frames, axis=0).astype(np.uint8)
                self.background_ready = True
                if self.debug:
                    print("Background stabilized with 60 frames - motion detection active")
            return False

        if not self.background_ready:
            return False

        # í”„ë ˆì„ ì°¨ì´ ê³„ì‚°
        frame_delta = cv2.absdiff(self.background_frame, gray)
        thresh = cv2.threshold(frame_delta, self.DELTA_THRESHOLD, 255, cv2.THRESH_BINARY)[1]

        # ë³€í™”í•œ í”½ì…€ ìˆ˜ ê³„ì‚°
        changed_pixels = cv2.countNonZero(thresh)

        # ë””ë²„ê·¸ ì¶œë ¥
        if self.debug and self.frame_count % 10 == 0:
            print(f"Simple Debug: {changed_pixels} changed pixels")

        # ì„ê³„ê°’ ì´ìƒ ë³€í™” ê°ì§€ ì‹œ
        if changed_pixels > self.threshold:
            if self.debug:
                print(f"Motion detected: {changed_pixels} changed pixels")
            self.last_detection_time = current_time
            return True

        # ì ì‘í˜• ë°°ê²½ ì—…ë°ì´íŠ¸
        if self.frame_count % self.BG_UPDATE_FAST == 0:
            self.background_frame = cv2.addWeighted(self.background_frame, 0.95, gray, 0.05, 0)

        return False
    
    def reset(self):
        """ê°ì§€ê¸° ìƒíƒœ ì´ˆê¸°í™”"""
        self.background_frame = None
        self.background_frames.clear()
        self.background_ready = False
        self.frame_count = 0
        self.last_detection_time = 0
    
    def is_ready(self) -> bool:
        """ê°ì§€ê¸° ì¤€ë¹„ ìƒíƒœ"""
        return self.background_ready

class HandWaveDetector(MotionDetectorBase):
    """ì† í”ë“¤ê¸° íŒ¨í„´ ê°ì§€ê¸°"""
    
    def __init__(self, cooldown: int = 8, debug: bool = True):
        self.cooldown = cooldown
        self.debug = debug
        self.last_detection_time = 0
        self.background_frame = None
        self.background_frames = deque(maxlen=30)
        self.background_ready = False
        self.hand_positions = []
        self.frame_count = 0
        
        # ì† ê°ì§€ íŒŒë¼ë¯¸í„°
        self.HAND_MIN_AREA = 800
        self.HAND_MAX_AREA = 80000
        self.GAUSSIAN_BLUR_SIZE = 11
        self.DELTA_THRESHOLD = 25
        self.WAVE_PATTERN_FRAMES = 4
        self.MOVEMENT_THRESHOLD = 15
    
    def detect(self, frame: np.ndarray) -> bool:
        """ì† í”ë“¤ê¸° ê°ì§€"""
        current_time = time.time()
        self.frame_count += 1

        # ì¿¨ë‹¤ìš´ ì²´í¬
        if current_time - self.last_detection_time < self.cooldown:
            return False

        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (self.GAUSSIAN_BLUR_SIZE, self.GAUSSIAN_BLUR_SIZE), 0)

        # ë°°ê²½ ì•ˆì •í™” ë‹¨ê³„ (ì²˜ìŒ 30í”„ë ˆì„)
        if len(self.background_frames) < 30:
            self.background_frames.append(gray.copy())
            if len(self.background_frames) == 30:
                self.background_frame = np.median(self.background_frames, axis=0).astype(np.uint8)
                self.background_ready = True
                if self.debug:
                    print("Background stabilized - hand wave detection active")
            return False

        if not self.background_ready:
            return False

        # ë°°ê²½ê³¼ í˜„ì¬ í”„ë ˆì„ì˜ ì°¨ì´ ê³„ì‚°
        frame_delta = cv2.absdiff(self.background_frame, gray)
        thresh = cv2.threshold(frame_delta, self.DELTA_THRESHOLD, 255, cv2.THRESH_BINARY)[1]

        # ë…¸ì´ì¦ˆ ì œê±° ë° ì† í˜•íƒœ ë³´ì¡´
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)
        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)

        # ì»¨íˆ¬ì–´ ì°¾ê¸°
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # ì† ëª¨ì–‘ í›„ë³´ ì°¾ê¸°
        hand_candidates = []
        for contour in contours:
            area = cv2.contourArea(contour)
            if self.HAND_MIN_AREA <= area <= self.HAND_MAX_AREA:
                perimeter = cv2.arcLength(contour, True)
                if perimeter > 0:
                    compactness = (4 * np.pi * area) / (perimeter * perimeter)
                    if 0.1 < compactness < 0.9:
                        M = cv2.moments(contour)
                        if M["m00"] > 0:
                            cx = int(M["m10"] / M["m00"])
                            cy = int(M["m01"] / M["m00"])
                            hand_candidates.append({
                                'center': (cx, cy),
                                'area': area,
                                'contour': contour,
                                'compactness': compactness
                            })

        # ì† ìœ„ì¹˜ ì¶”ì  ë° íŒ¨í„´ ë¶„ì„
        if hand_candidates:
            largest_hand = max(hand_candidates, key=lambda x: x['area'])
            self.hand_positions.append(largest_hand['center'])

            if len(self.hand_positions) > self.WAVE_PATTERN_FRAMES:
                self.hand_positions.pop(0)

            if len(self.hand_positions) >= self.WAVE_PATTERN_FRAMES:
                wave_detected = self._analyze_wave_pattern()
                if wave_detected:
                    self.last_detection_time = current_time
                    self.hand_positions.clear()
                    return True
        else:
            if len(self.hand_positions) > 0:
                self.hand_positions.pop(0)

        # ëŠë¦° ë°°ê²½ ì—…ë°ì´íŠ¸
        if self.frame_count % 20 == 0:
            self.background_frame = cv2.addWeighted(self.background_frame, 0.95, gray, 0.05, 0)

        return False
    
    def _analyze_wave_pattern(self) -> bool:
        """ì† ìœ„ì¹˜ë¡œ í”ë“¤ê¸° íŒ¨í„´ ë¶„ì„"""
        if len(self.hand_positions) < self.WAVE_PATTERN_FRAMES:
            return False

        x_positions = [pos[0] for pos in self.hand_positions]
        x_min, x_max = min(x_positions), max(x_positions)
        x_range = x_max - x_min

        if x_range < self.MOVEMENT_THRESHOLD:
            return False

        direction_changes = 0
        for i in range(1, len(x_positions) - 1):
            if ((x_positions[i] > x_positions[i-1] and x_positions[i] > x_positions[i+1]) or
                (x_positions[i] < x_positions[i-1] and x_positions[i] < x_positions[i+1])):
                direction_changes += 1

        if direction_changes >= 1:
            if self.debug:
                print(f"Wave pattern detected: range={x_range}px, changes={direction_changes}")
            return True

        return False
    
    def reset(self):
        """ê°ì§€ê¸° ìƒíƒœ ì´ˆê¸°í™”"""
        self.background_frame = None
        self.background_frames.clear()
        self.background_ready = False
        self.hand_positions.clear()
        self.frame_count = 0
        self.last_detection_time = 0
    
    def is_ready(self) -> bool:
        """ê°ì§€ê¸° ì¤€ë¹„ ìƒíƒœ"""
        return self.background_ready

# ============================================================================
# 4. ì˜ìƒ ë…¹í™” ê´€ë¦¬ í´ë˜ìŠ¤ (EXTRACTED from SimpleMotionDetector)
# ============================================================================

class VideoRecorder:
    """í”„ë¦¬ë²„í¼ë§ì„ ì§€ì›í•˜ëŠ” ì˜ìƒ ë…¹í™” ì „ë‹´ í´ë˜ìŠ¤"""
    
    def __init__(self, output_dir: str = "videos/motion_events/cam0", 
                 width: int = 1280, height: int = 720, 
                 pre_buffer: int = 10, post_buffer: int = 20):
        self.output_dir = Path(output_dir)
        self.width = width
        self.height = height
        self.pre_buffer = pre_buffer    # ëª¨ì…˜ ì´ì „ ë²„í¼ ì‹œê°„
        self.post_buffer = post_buffer  # ëª¨ì…˜ ì´í›„ ë…¹í™” ì‹œê°„
        self.duration = pre_buffer + post_buffer  # ì´ ë…¹í™” ì‹œê°„
        
        self.is_recording = False
        self.recording_process = None
        self.current_recording_path = None
        self.current_temp_files = []  # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì„ì‹œ íŒŒì¼ë“¤
        self.merge_thread = None  # ë³‘í•© ìŠ¤ë ˆë“œ ì¶”ì 
        self.merge_thread_stop = threading.Event()  # ìŠ¤ë ˆë“œ ì¢…ë£Œ ì‹ í˜¸
        
        # í”„ë¦¬ë²„í¼ë§ì„ ìœ„í•œ ë³€ìˆ˜ (í”„ë ˆì„ ê¸°ë°˜)
        self.buffer_dir = None
        # skip_framesë¥¼ ê³ ë ¤í•œ ì‹¤ì œ fps ê³„ì‚° (30fps / 3 = 10fps)
        self.actual_buffer_fps = FRAMERATE // SKIP_FRAME  # 30 / 3 = 10fps
        self.frame_buffer = deque(maxlen=pre_buffer * self.actual_buffer_fps)  # 5ì´ˆ * 10fps = 50 í”„ë ˆì„
        self.buffer_lock = threading.Lock()
        self.frame_count = 0
        self.last_buffer_save_time = 0
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        self.buffer_dir = Path(tempfile.mkdtemp(prefix="motion_buffer_"))
    
    def add_frame_to_buffer(self, frame: np.ndarray):
        """í”„ë ˆì„ì„ ë²„í¼ì— ì¶”ê°€ (ëª¨ì…˜ ê°ì§€ ìŠ¤íŠ¸ë¦¼ì—ì„œ í˜¸ì¶œ)"""
        with self.buffer_lock:
            # JPEGë¡œ ì¸ì½”ë”©í•˜ì—¬ ì €ì¥ (ë©”ëª¨ë¦¬ íš¨ìœ¨)
            _, jpeg_data = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
            self.frame_buffer.append(jpeg_data)
            self.frame_count += 1
            
            # 1ì´ˆë§ˆë‹¤ ë²„í¼ ìƒíƒœ ì¶œë ¥
            current_time = time.time()
            if current_time - self.last_buffer_save_time >= 1:
                buffer_seconds = len(self.frame_buffer) / self.actual_buffer_fps  # ì‹¤ì œ ì €ì¥ fpsë¡œ ê³„ì‚°
                if self.frame_count % 10 == 0:  # 10fps ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½
                    print(f"Buffer: {buffer_seconds:.1f}s ({len(self.frame_buffer)} frames @ {self.actual_buffer_fps}fps)")
                self.last_buffer_save_time = current_time
    
    def save_buffer_to_file(self) -> Optional[Path]:
        """í˜„ì¬ ë²„í¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        if not self.frame_buffer:
            return None
            
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        buffer_file = self.buffer_dir / f"buffer_{timestamp}.mp4"
        
        try:
            # OpenCV VideoWriter ì‚¬ìš© - 30fpsë¡œ ì„¤ì • (í˜¸í™˜ì„±ì„ ìœ„í•´)
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(str(buffer_file), fourcc, 30.0, (self.width, self.height))  # 30fpsë¡œ ì„¤ì •
            
            # í”„ë ˆì„ ë³´ê°„: 10fps â†’ 30fps (3ë°° ë³µì‚¬)
            frame_duplication = 3  # 30fps / 10fps = 3
            
            with self.buffer_lock:
                for jpeg_data in self.frame_buffer:
                    frame = cv2.imdecode(jpeg_data, cv2.IMREAD_COLOR)
                    if frame is not None:
                        # í•´ìƒë„ ë³€í™˜ (640x480 -> 1280x720)
                        frame_resized = cv2.resize(frame, (self.width, self.height))
                        # ê°™ì€ í”„ë ˆì„ì„ 3ë²ˆ ì“°ê¸° (10fps â†’ 30fps ë³€í™˜)
                        for _ in range(frame_duplication):
                            out.write(frame_resized)
            
            out.release()
            
            if buffer_file.exists():
                # ë²„í¼ íŒŒì¼ í¬ê¸°ì™€ ì˜ˆìƒ ì‹œê°„ ì¶œë ¥
                file_size = buffer_file.stat().st_size / (1024 * 1024)
                frames_saved = len(self.frame_buffer)
                expected_seconds = frames_saved / self.actual_buffer_fps
                
                # í”„ë¦¬ë²„í¼ duration í™•ì¸
                duration_check = subprocess.run(
                    ["ffprobe", "-v", "error", "-show_entries", "format=duration",
                     "-of", "default=noprint_wrappers=1:nokey=1", str(buffer_file)],
                    capture_output=True, timeout=5
                )
                
                if duration_check.returncode == 0:
                    actual_duration = float(duration_check.stdout.decode().strip())
                    print(f"Pre-buffer saved: {buffer_file.name}")
                    print(f"  - Frames: {frames_saved} frames @ {self.actual_buffer_fps}fps capture")
                    print(f"  - Duration: {actual_duration:.1f}s (expected: {expected_seconds:.1f}s)")
                    print(f"  - File size: {file_size:.1f}MB")
                    
                    # Duration ê²½ê³ 
                    if abs(actual_duration - expected_seconds) > 0.5:
                        print(f"  âš ï¸ Warning: Duration mismatch! Check fps settings.")
                else:
                    print(f"Pre-buffer saved: {buffer_file.name} ({file_size:.1f}MB, {frames_saved} frames = {expected_seconds:.1f}s)")
                
                return buffer_file
            else:
                return None
                
        except Exception as e:
            print(f"Buffer save error: {e}")
            return None
    
    def cleanup_buffer(self):
        """ë²„í¼ ì •ë¦¬"""
        if self.buffer_dir and self.buffer_dir.exists():
            try:
                shutil.rmtree(self.buffer_dir)
            except:
                pass
        self.frame_buffer.clear()
        
        # ë³‘í•© ìŠ¤ë ˆë“œ ì¢…ë£Œ ì‹ í˜¸
        self.merge_thread_stop.set()
    
    def cleanup_temp_files(self):
        """ëª¨ë“  ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
        # ì¶”ì  ì¤‘ì¸ ì„ì‹œ íŒŒì¼ ì‚­ì œ
        for temp_file in self.current_temp_files:
            if temp_file.exists():
                try:
                    temp_file.unlink()
                    print(f"Cleaned up temp file: {temp_file.name}")
                except Exception as e:
                    print(f"Failed to delete temp file {temp_file.name}: {e}")
        
        # output_dir ë° í•˜ìœ„ ë‚ ì§œ í´ë”ì˜ ëª¨ë“  temp_*.h264 íŒŒì¼ ì •ë¦¬
        if self.output_dir.exists():
            # ë©”ì¸ ë””ë ‰í† ë¦¬ì˜ ì„ì‹œ íŒŒì¼
            for temp_file in self.output_dir.glob("temp_*.h264"):
                try:
                    temp_file.unlink()
                    print(f"Cleaned up orphaned temp file: {temp_file.name}")
                except Exception as e:
                    print(f"Failed to delete temp file {temp_file.name}: {e}")
            
            # ë‚ ì§œ í´ë” ë‚´ì˜ ì„ì‹œ íŒŒì¼
            for date_folder in self.output_dir.glob("[0-9][0-9][0-9][0-9][0-9][0-9]"):
                for temp_file in date_folder.glob("temp_*.h264"):
                    try:
                        temp_file.unlink()
                        print(f"Cleaned up temp file: {date_folder.name}/{temp_file.name}")
                    except Exception as e:
                        print(f"Failed to delete temp file: {e}")
        
        # concat ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬
        if self.output_dir.exists():
            # ë©”ì¸ ë””ë ‰í† ë¦¬ì˜ concat íŒŒì¼
            for list_file in self.output_dir.glob("concat_*.txt"):
                try:
                    list_file.unlink()
                    print(f"Cleaned up list file: {list_file.name}")
                except Exception as e:
                    print(f"Failed to delete list file {list_file.name}: {e}")
            
            # ë‚ ì§œ í´ë” ë‚´ì˜ concat íŒŒì¼
            for date_folder in self.output_dir.glob("[0-9][0-9][0-9][0-9][0-9][0-9]"):
                for list_file in date_folder.glob("concat_*.txt"):
                    try:
                        list_file.unlink()
                        print(f"Cleaned up list file: {date_folder.name}/{list_file.name}")
                    except Exception as e:
                        print(f"Failed to delete list file: {e}")
        
        self.current_temp_files.clear()
    
    def start_recording(self, camera_id: int) -> Optional[Path]:
        """í”„ë¦¬ë²„í¼ì™€ í¬ìŠ¤íŠ¸ ë…¹í™”ë¥¼ ë³‘í•©í•œ ì˜ìƒ ë…¹í™”"""
        if self.is_recording:
            return None
            
        # ë‚ ì§œë³„ í´ë” ìƒì„± (YYMMDD í˜•ì‹)
        now = datetime.now()
        date_folder = now.strftime("%y%m%d")  # YYMMDD í˜•ì‹
        daily_dir = self.output_dir / date_folder
        daily_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = now.strftime("%Y%m%d_%H%M%S")
        output_path = daily_dir / f"motion_event_cam0_{timestamp}.mp4"  # ë‚ ì§œ í´ë” ì•ˆì— ì €ì¥
        self.current_recording_path = output_path
        
        print("\n" + "="*60)
        print(f"ğŸ¬ Motion Event Recording Started")
        print(f"  Pre-buffer: {self.pre_buffer}s (from circular buffer)")
        print(f"  Post-buffer: {self.post_buffer}s (new recording)")
        print(f"  Expected total: {self.pre_buffer + self.post_buffer}s")
        print("="*60)
        
        try:
            self.is_recording = True
            
            # 1. í˜„ì¬ ë²„í¼ ì €ì¥
            buffer_file = self.save_buffer_to_file()
            
            if not buffer_file:
                print("Warning: No pre-buffer available")
            
            # 2. í¬ìŠ¤íŠ¸ ë²„í¼ ë…¹í™” (ìŠ¤íŠ¸ë¦¼ ì¤‘ë‹¨ í•„ìš”)
            temp_post_file = daily_dir / f"temp_post_{timestamp}.h264"  # ë‚ ì§œ í´ë”ì— ì„ì‹œ íŒŒì¼ ìƒì„±
            self.current_temp_files.append(temp_post_file)  # ì„ì‹œ íŒŒì¼ ì¶”ì 
            
            recording_cmd = [
                "rpicam-vid",
                "--camera", str(camera_id),
                "--width", str(self.width),
                "--height", str(self.height),
                "--framerate", "30",  # 30fpsë¡œ í†µì¼
                "--timeout", str(self.post_buffer * 1000),
                "--nopreview",
                "--codec", "h264",
                "--output", str(temp_post_file)
            ]
            
            print(f"Recording {self.post_buffer}s post-buffer...")
            self.recording_process = subprocess.Popen(
                recording_cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                preexec_fn=os.setsid
            )
            
            # 3. ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë³‘í•© ì‘ì—… ìˆ˜í–‰
            def merge_worker():
                try:
                    # í¬ìŠ¤íŠ¸ ë²„í¼ ë…¹í™” ì™„ë£Œ ëŒ€ê¸°
                    self.recording_process.wait(timeout=self.post_buffer + 5)
                    
                    if temp_post_file.exists():
                        # íŒŒì¼ ë³‘í•©
                        files_to_merge = []
                        if buffer_file and buffer_file.exists():
                            files_to_merge.append(buffer_file)
                        files_to_merge.append(temp_post_file)
                        
                        if len(files_to_merge) > 1:
                            print(f"\nğŸ“¼ Merging videos:")
                            print(f"  1. Pre-buffer: {buffer_file.name if buffer_file else 'None'} ({self.pre_buffer}s)")
                            print(f"  2. Post-buffer: {temp_post_file.name} ({self.post_buffer}s)")
                            self._merge_video_files(files_to_merge, output_path)
                        else:
                            # ë²„í¼ê°€ ì—†ìœ¼ë©´ í¬ìŠ¤íŠ¸ íŒŒì¼ë§Œ ì‚¬ìš©
                            print(f"âš ï¸ No pre-buffer available, using post-buffer only ({self.post_buffer}s)")
                            shutil.move(str(temp_post_file), str(output_path))
                        
                        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                        if temp_post_file.exists():
                            temp_post_file.unlink()
                        if buffer_file and buffer_file.exists():
                            buffer_file.unlink()
                        
                        print(f"Recording saved: {output_path.name}")
                    else:
                        print("Post-buffer recording failed")
                        
                except Exception as e:
                    print(f"Merge error: {e}")
                finally:
                    self.is_recording = False
                    self.current_recording_path = None
                    self.current_temp_files.clear()  # ì„ì‹œ íŒŒì¼ ëª©ë¡ ì •ë¦¬
            
            # ë³‘í•© ìŠ¤ë ˆë“œ ì‹œì‘ (daemon=Falseë¡œ ë³€ê²½í•˜ì—¬ ì •ìƒ ì¢…ë£Œ ë³´ì¥)
            self.merge_thread = threading.Thread(target=merge_worker, daemon=False)
            self.merge_thread.start()
            
            return output_path
            
        except Exception as e:
            print(f"Recording error: {e}")
            self.is_recording = False
            return None
    
    def _merge_video_files(self, input_files: List[Path], output_file: Path):
        """ì—¬ëŸ¬ ë¹„ë””ì˜¤ íŒŒì¼ì„ í•˜ë‚˜ì˜ MP4ë¡œ ë³‘í•©"""
        try:
            # íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            list_file = output_file.parent / f"concat_{output_file.stem}.txt"
            with open(list_file, 'w') as f:
                for file in input_files:
                    if file.exists():
                        # mp4ì™€ h264 íŒŒì¼ ì²˜ë¦¬
                        if file.suffix == '.mp4':
                            # mp4ë¥¼ h264ë¡œ ë³€í™˜ (í”„ë ˆì„ë ˆì´íŠ¸ í†µì¼)
                            temp_h264 = file.parent / f"{file.stem}.h264"
                            extract_cmd = [
                                "ffmpeg", "-i", str(file),
                                "-c:v", "copy", "-an",
                                "-r", "30",  # 30fpsë¡œ í†µì¼
                                "-y", str(temp_h264)
                            ]
                            subprocess.run(extract_cmd, capture_output=True, timeout=15)
                            if temp_h264.exists():
                                f.write(f"file '{temp_h264.absolute()}'\n")
                        else:
                            f.write(f"file '{file.absolute()}'\n")
            
            # ffmpegìœ¼ë¡œ ë³‘í•© (30ì´ˆë¡œ ì œí•œ)
            merge_cmd = [
                "ffmpeg",
                "-f", "concat",
                "-safe", "0",
                "-i", str(list_file),
                "-c:v", "libx264",  # h264 ì½”ë± ì‚¬ìš©
                "-preset", "fast",  # ì¸ì½”ë”© ì†ë„ í–¥ìƒ
                "-t", "30",         # 30ì´ˆë¡œ ì œí•œ
                "-r", "30",         # 30fpsë¡œ í†µì¼
                "-pix_fmt", "yuv420p",  # í˜¸í™˜ì„± í–¥ìƒ
                "-y",
                str(output_file)
            ]
            
            result = subprocess.run(merge_cmd, capture_output=True, timeout=60)  # 30ì´ˆ â†’ 60ì´ˆë¡œ ì¦ê°€
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            list_file.unlink()
            for file in input_files:
                if file.suffix == '.mp4':
                    temp_h264 = file.parent / f"{file.stem}.h264"
                    if temp_h264.exists():
                        temp_h264.unlink()
            
            if result.returncode == 0:
                file_size = output_file.stat().st_size / (1024 * 1024)
                
                # ë³‘í•©ëœ ë¹„ë””ì˜¤ì˜ ì‹¤ì œ duration í™•ì¸
                duration_check = subprocess.run(
                    ["ffprobe", "-v", "error", "-show_entries", "format=duration",
                     "-of", "default=noprint_wrappers=1:nokey=1", str(output_file)],
                    capture_output=True, timeout=5
                )
                
                if duration_check.returncode == 0:
                    actual_duration = float(duration_check.stdout.decode().strip())
                    print(f"\nâœ… Video merged successfully: {output_file.name}")
                    print(f"  - File size: {file_size:.1f}MB")
                    print(f"  - Final duration: {actual_duration:.1f}s")
                    print(f"  - Expected: 30s (pre:{self.pre_buffer}s + post:{self.post_buffer}s)")
                    print(f"  - Difference: {actual_duration-30:+.1f}s")
                    
                    # í”„ë¦¬ë²„í¼ í¬í•¨ ì—¬ë¶€ í™•ì¸
                    if abs(actual_duration - 30) < 0.5:
                        print(f"  âœ“ Pre-buffer successfully included in final video")
                    elif actual_duration < 28:
                        print(f"  âš ï¸ Pre-buffer may be missing or incomplete")
                    else:
                        print(f"  âœ“ Duration check passed")
                else:
                    print(f"\nâœ… Video merged: {output_file.name} ({file_size:.1f}MB)")
                    print(f"  âš ï¸ Duration verification failed")
                
                return True
            else:
                print(f"Merge failed: {result.stderr.decode()[:200]}")
                return False
                
        except Exception as e:
            print(f"Merge error: {e}")
            return False
    
    def wait_for_completion(self) -> bool:
        """ë…¹í™” ì™„ë£Œ ëŒ€ê¸°"""
        if not self.recording_process:
            return False
            
        try:
            stdout, stderr = self.recording_process.communicate(timeout=self.duration + 10)
            success = self.recording_process.returncode == 0
            self.is_recording = False
            self.current_recording_path = None  # ë…¹í™” ì™„ë£Œ ì‹œ ê²½ë¡œ ì´ˆê¸°í™”
            return success
        except subprocess.TimeoutExpired:
            self.stop_recording()
            return False
    
    def stop_recording(self):
        """ì˜ìƒ ë…¹í™” ì¤‘ì§€"""
        if self.recording_process and self.recording_process.poll() is None:
            try:
                # SIGTERM ë¨¼ì € ì‹œë„
                os.killpg(os.getpgid(self.recording_process.pid), signal.SIGTERM)
                try:
                    self.recording_process.wait(timeout=2)
                except subprocess.TimeoutExpired:
                    # SIGKILLë¡œ ê°•ì œ ì¢…ë£Œ
                    os.killpg(os.getpgid(self.recording_process.pid), signal.SIGKILL)
                    self.recording_process.wait(timeout=1)
            except:
                pass
        
        # ë³‘í•© ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
        if self.merge_thread and self.merge_thread.is_alive():
            print("Waiting for merge thread to complete...")
            self.merge_thread_stop.set()
            self.merge_thread.join(timeout=3)
            if self.merge_thread.is_alive():
                print("Warning: Merge thread still running")
        
        self.is_recording = False
        # current_recording_pathëŠ” check_and_cleanup_recordingì—ì„œ ì²˜ë¦¬
    
    def is_recording_active(self) -> bool:
        """ë…¹í™” ìƒíƒœ í™•ì¸"""
        return self.is_recording
    
    def check_and_cleanup_recording(self) -> bool:
        """ì¤‘ë‹¨ëœ ë…¹í™” íŒŒì¼ í™•ì¸ ë° ì •ë¦¬"""
        if not self.current_recording_path:
            return True
            
        file_path = self.current_recording_path
        
        # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not file_path.exists():
            print(f"Recording file not found: {file_path.name}")
            self.current_recording_path = None
            return False
            
        # íŒŒì¼ í¬ê¸° í™•ì¸ (ìµœì†Œ í¬ê¸° 1KB)
        file_size = file_path.stat().st_size
        if file_size < 1024:
            print(f"Recording file too small ({file_size} bytes), deleting: {file_path.name}")
            try:
                file_path.unlink()
                print(f"Deleted corrupted file: {file_path.name}")
            except Exception as e:
                print(f"Failed to delete corrupted file: {e}")
            self.current_recording_path = None
            return False
            
        # ffprobeë¡œ íŒŒì¼ ë¬´ê²°ì„± í™•ì¸
        try:
            check_cmd = [
                "ffprobe",
                "-v", "error",
                "-show_entries", "format=duration",
                "-of", "default=noprint_wrappers=1:nokey=1",
                str(file_path)
            ]
            result = subprocess.run(check_cmd, capture_output=True, timeout=5)
            
            if result.returncode != 0:
                print(f"Recording file is corrupted, deleting: {file_path.name}")
                try:
                    file_path.unlink()
                    print(f"Deleted corrupted file: {file_path.name}")
                except Exception as e:
                    print(f"Failed to delete corrupted file: {e}")
                self.current_recording_path = None
                return False
            else:
                # íŒŒì¼ì´ ì •ìƒì¸ ê²½ìš°
                file_size_mb = file_size / (1024 * 1024)
                print(f"Recording file is valid: {file_path.name} ({file_size_mb:.1f}MB)")
                self.current_recording_path = None
                return True
                
        except subprocess.TimeoutExpired:
            print(f"ffprobe timeout, file may be corrupted: {file_path.name}")
            self.current_recording_path = None
            return False
        except FileNotFoundError:
            print("ffprobe not found, cannot verify file integrity")
            print(f"Recording file saved but not verified: {file_path.name}")
            self.current_recording_path = None
            return True
        except Exception as e:
            print(f"Error checking file integrity: {e}")
            self.current_recording_path = None
            return False

# ============================================================================
# 5. ì´ë²¤íŠ¸ ê´€ë¦¬ í´ë˜ìŠ¤ (NEW)
# ============================================================================

class MotionEvent:
    """ëª¨ì…˜ ê°ì§€ ì´ë²¤íŠ¸"""
    def __init__(self, timestamp: datetime, detector_type: str, confidence: float = 0.0):
        self.timestamp = timestamp
        self.detector_type = detector_type
        self.confidence = confidence
        self.video_path = None

class EventManager:
    """ì´ë²¤íŠ¸ ê´€ë¦¬ ë° ë¡œê¹…"""
    
    def __init__(self, debug: bool = True):
        self.events = []
        self.debug = debug
    
    def handle_motion_detected(self, event: MotionEvent):
        """ëª¨ì…˜ ê°ì§€ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        self.events.append(event)
        if self.debug:
            timestamp = event.timestamp.strftime("%Y-%m-%d %H:%M:%S")
            print(f"[{timestamp}] ëª¨ì…˜ì´ ë””í…ë˜ì—ˆìŠµë‹ˆë‹¤. ({event.detector_type})")
    
    def handle_recording_completed(self, event: MotionEvent, video_path: Path, success: bool):
        """ë…¹í™” ì™„ë£Œ ì´ë²¤íŠ¸ ì²˜ë¦¬"""
        if success and video_path.exists():
            event.video_path = video_path
            file_size = video_path.stat().st_size / (1024 * 1024)
            if self.debug:
                print(f"Recording completed: {video_path.name} ({file_size:.1f}MB)")
        else:
            if self.debug:
                print(f"Recording failed: {video_path.name if video_path else 'Unknown'}")
    
    def get_recent_events(self, count: int = 10) -> List[MotionEvent]:
        """ìµœê·¼ ì´ë²¤íŠ¸ ì¡°íšŒ"""
        return self.events[-count:]

# ============================================================================
# 6. ëª¨ì…˜ ê°ì§€ê¸° íŒ©í† ë¦¬ (NEW)
# ============================================================================

class MotionDetectorFactory:
    """ëª¨ì…˜ ê°ì§€ê¸° ìƒì„± íŒ©í† ë¦¬"""
    
    @staticmethod
    def create_detector(config: dict) -> MotionDetectorBase:
        """ì„¤ì •ì— ë”°ë¼ ì ì ˆí•œ ê°ì§€ê¸° ìƒì„±"""
        detector_type = config.get('type', 'simple')
        threshold = config.get('threshold', 7000)
        cooldown = config.get('cooldown', 8)
        debug = config.get('debug', True)
        
        if detector_type == 'simple':
            return SimpleMotionDetector(threshold=threshold, cooldown=cooldown, debug=debug)
        elif detector_type == 'hand_wave':
            return HandWaveDetector(cooldown=cooldown, debug=debug)
        else:
            raise ValueError(f"Unknown detector type: {detector_type}")

# ============================================================================
# 7. ë©”ì¸ ì‹œìŠ¤í…œ ì¡°ì •ì í´ë˜ìŠ¤ (REPLACES SimpleMotionDetector)
# ============================================================================

class MotionDetectionSystem:
    """ëª¨ì…˜ ê°ì§€ ì‹œìŠ¤í…œ ì „ì²´ ì¡°ì •ì"""
    
    def __init__(self, config: Config):
        self.config = config
        self.running = False
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.camera_manager = CameraStreamManager(
            camera_id=config.camera.get('id', 0),
            width=config.camera.get('width', 640),
            height=config.camera.get('height', 480),
            framerate=config.camera.get('framerate', 30)
        )
        
        self.motion_detector = MotionDetectorFactory.create_detector({
            'type': config.detection.get('type', 'simple'),
            'threshold': config.detection.get('threshold', 7000),
            'cooldown': config.detection.get('cooldown', 8),
            'debug': config.debug.get('output', True)
        })
        
        if config.recording.get('enabled', True):
            self.video_recorder = VideoRecorder(
                output_dir=config.recording.get('output_dir', 'videos/motion_events/cam0'),
                width=config.recording.get('width', 1280),
                height=config.recording.get('height', 720),
                pre_buffer=config.recording.get('pre_buffer', 10),
                post_buffer=config.recording.get('post_buffer', 20)
            )
        else:
            self.video_recorder = None
        
        self.event_manager = EventManager(debug=config.debug.get('output', True))
        
        # ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ì„¤ì •
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
        self._print_startup_info()
    
    def _print_startup_info(self):
        """ì‹œì‘ ì •ë³´ ì¶œë ¥"""
        print(f"Motion Detection System Initialized - Camera 0")
        print(f"   Camera: {self.config.camera.get('width')}x{self.config.camera.get('height')}")
        print(f"   Detector: {self.config.detection.get('type').upper()}")
        print(f"   {self.config.get_sensitivity_info()}")
        print(f"   Recording: {self.config.recording.get('enabled')}")
        if self.video_recorder:
            print(f"   Recording Resolution: {self.config.recording.get('width')}x{self.config.recording.get('height')}")
            print(f"   Pre-buffer: {self.config.recording.get('pre_buffer', 5)}s (@ {FRAMERATE//SKIP_FRAME}fps capture)")
            print(f"   Post-buffer: {self.config.recording.get('post_buffer', 25)}s (@ 30fps capture)")
            print(f"   Total Duration: {self.config.recording.get('duration', 30)}s")
        print()
        print("ğŸ”§ ì„¤ì • ë³€ê²½ ë°©ë²•:")
        print("   ë¯¼ê°ë„ ë³€ê²½: ì½”ë“œ ìƒë‹¨ì˜ CURRENT_SENSITIVITY ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.")
        print("   ê°ì§€ê¸° ë³€ê²½: ì½”ë“œ ìƒë‹¨ì˜ DETECTOR_TYPE ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.")
        print()
        print(self.config.list_available_sensitivities())
        print()
    
    def _signal_handler(self, _signum, _frame):
        """ì‹œê·¸ë„ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ ì¢…ë£Œ"""
        print("\nShutting down motion detection system...")
        
        # ë…¹í™” ì¤‘ì¸ íŒŒì¼ í™•ì¸ ë° ì •ë¦¬
        if self.video_recorder:
            if self.video_recorder.current_recording_path:
                print(f"Checking interrupted recording: {self.video_recorder.current_recording_path.name}")
            
            # ë…¹í™” í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
            self.video_recorder.stop_recording()
            time.sleep(1)  # íŒŒì¼ ì“°ê¸° ì™„ë£Œ ëŒ€ê¸°
            
            if self.video_recorder.current_recording_path:
                self.video_recorder.check_and_cleanup_recording()
            
            # ì„ì‹œ íŒŒì¼ë“¤ ì •ë¦¬
            print("Cleaning up temporary files...")
            self.video_recorder.cleanup_temp_files()
        
        # ì‹œìŠ¤í…œ ì¢…ë£Œ
        self.stop()
        
        # ëª¨ë“  ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
        print("Waiting for all threads to complete...")
        for thread in threading.enumerate():
            if thread != threading.main_thread() and thread.is_alive():
                thread.join(timeout=1)
        
        print("Shutdown complete")
        sys.exit(0)
    
    def start(self):
        """ì‹œìŠ¤í…œ ì‹œì‘"""
        # ì¹´ë©”ë¼ í…ŒìŠ¤íŠ¸
        print("Testing camera...")
        if not self.camera_manager.test_camera():
            print("Camera test failed")
            return False
        print("Camera OK")
        
        # ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì‹œì‘ (í”„ë¦¬ë²„í¼ë§ê³¼ ëª¨ì…˜ ê°ì§€ë¥¼ ë™ì‹œì— ìˆ˜í–‰)
        if not self.camera_manager.start_stream():
            print("Failed to start camera stream")
            return False
        
        self.running = True
        print("Motion detection started (Ctrl+C to stop)")
        if self.video_recorder:
            actual_fps = FRAMERATE // SKIP_FRAME
            buffer_frames = self.config.recording.get('pre_buffer', 5) * actual_fps
            print(f"Pre-buffering enabled: {self.config.recording.get('pre_buffer', 5)}s circular buffer")
            print(f"  - Capture rate: {actual_fps}fps (every {SKIP_FRAME} frames)")
            print(f"  - Buffer capacity: {buffer_frames} frames")
        print("Monitoring for motion...")
        
        self._run_detection_loop()
        return True
    
    def stop(self):
        """ì‹œìŠ¤í…œ ì¤‘ì§€"""
        self.running = False
        
        # ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€
        if self.camera_manager:
            self.camera_manager.stop_stream()
        
        if self.video_recorder:
            # ë…¹í™” ì¤‘ì¸ ê²½ìš° ì¤‘ì§€
            if self.video_recorder.is_recording:
                self.video_recorder.stop_recording()
                time.sleep(1)  # íŒŒì¼ ì“°ê¸° ì™„ë£Œ ëŒ€ê¸°
                if self.video_recorder.current_recording_path:
                    self.video_recorder.check_and_cleanup_recording()
            
            # ë²„í¼ ì •ë¦¬
            self.video_recorder.cleanup_buffer()
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            self.video_recorder.cleanup_temp_files()
        
        print("Motion detection system stopped")
    
    def _run_detection_loop(self):
        """ë©”ì¸ ê°ì§€ ë£¨í”„"""
        frame_count = 0
        skip_frames = self.config.detection.get('skip_frames', 3)
        
        try:
            while self.running:
                # í”„ë¡œì„¸ìŠ¤ ìƒì¡´ í™•ì¸
                if not self.camera_manager.is_streaming():
                    print("Camera stream died")
                    break

                # í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°
                frame = self.camera_manager.get_frame()
                if frame is None:
                    continue

                frame_count += 1

                # í”„ë¦¬ë²„í¼ë§ì— í”„ë ˆì„ ì¶”ê°€ (ë…¹í™” í™œì„±í™”ëœ ê²½ìš°)
                if self.video_recorder and not self.video_recorder.is_recording:
                    self.video_recorder.add_frame_to_buffer(frame)
                
                # í”„ë ˆì„ ê±´ë„ˆë›°ê¸°(ë¶€í•˜ ê°ì†Œ)
                if frame_count % skip_frames != 0:
                    continue

                # ëª¨ì…˜ ê°ì§€
                motion_detected = self.motion_detector.detect(frame)

                if motion_detected:
                    # ì´ë²¤íŠ¸ ìƒì„±
                    event = MotionEvent(
                        timestamp=datetime.now(),
                        detector_type=type(self.motion_detector).__name__
                    )
                    
                    # ì´ë²¤íŠ¸ ì²˜ë¦¬
                    self.event_manager.handle_motion_detected(event)
                    
                    # ë…¹í™” íŠ¸ë¦¬ê±° (ë™ê¸°ì‹ìœ¼ë¡œ ë³€ê²½)
                    if self.video_recorder:
                        self._trigger_recording_sync(event)

                # 300í”„ë ˆì„ë§ˆë‹¤ ìƒíƒœ ì¶œë ¥
                if frame_count % 300 == 0:
                    timestamp = datetime.now().strftime("%H:%M:%S")
                    print(f"[{timestamp}] Processed {frame_count} frames")

        except KeyboardInterrupt:
            print("\nUser interrupted")
        except Exception as e:
            print(f"Detection error: {e}")
        finally:
            self.stop()
    
    def _trigger_recording_sync(self, event: MotionEvent):
        """í”„ë¦¬ë²„í¼ì™€ í¬ìŠ¤íŠ¸ ë…¹í™”ë¥¼ í™œìš©í•œ ë…¹í™” íŠ¸ë¦¬ê±°"""
        # í¬ìŠ¤íŠ¸ ë²„í¼ ë…¹í™”ë¥¼ ìœ„í•´ ìŠ¤íŠ¸ë¦¼ ì¤‘ì§€ í•„ìš”
        print("Stopping detection stream for post-buffer recording...")
        self.camera_manager.stop_stream()
        
        # ë…¹í™” ìˆ˜í–‰ (í”„ë¦¬ë²„í¼ + í¬ìŠ¤íŠ¸ë²„í¼)
        video_path = self.video_recorder.start_recording(self.camera_manager.camera_id)
        
        if video_path:
            # í¬ìŠ¤íŠ¸ ë²„í¼ ë…¹í™” ì™„ë£Œ ëŒ€ê¸° (ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§„í–‰)
            print(f"Post-buffer recording in progress...")
            time.sleep(self.config.recording.get('post_buffer', 20) + 2)
            
            self.event_manager.handle_recording_completed(event, video_path, True)
        
        # ìŠ¤íŠ¸ë¦¼ ì¬ì‹œì‘
        print("Restarting detection stream...")
        if self.camera_manager.restart_stream():
            print("Detection stream resumed")
        else:
            print("Failed to restart detection stream")
            self.running = False

# ============================================================================
# 8. ë©”ì¸ í•¨ìˆ˜ (MODIFIED)
# ============================================================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("Motion Detection System - Camera 0")
    print("=" * 40)
    
    # ì„¤ì • ë¡œë“œ
    config = Config()  # ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
    
    # ì‹œìŠ¤í…œ ì‹œì‘
    system = MotionDetectionSystem(config)
    system.start()

if __name__ == "__main__":
    main()